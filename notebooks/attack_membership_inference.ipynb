{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running membership inference attacks on the Nursery data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will show how to run black-box membership attacks. This will be demonstrated on the Nursery dataset (original dataset can be found here: https://archive.ics.uci.edu/ml/datasets/nursery). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already preprocessed the dataset such that all categorical features are one-hot encoded, and the data was scaled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>children</th>\n",
       "      <th>parents_pretentious</th>\n",
       "      <th>parents_usual</th>\n",
       "      <th>parents_great_pret</th>\n",
       "      <th>has_nurs_very_crit</th>\n",
       "      <th>has_nurs_critical</th>\n",
       "      <th>has_nurs_proper</th>\n",
       "      <th>has_nurs_improper</th>\n",
       "      <th>has_nurs_less_proper</th>\n",
       "      <th>...</th>\n",
       "      <th>housing_less_conv</th>\n",
       "      <th>housing_critical</th>\n",
       "      <th>finance_convenient</th>\n",
       "      <th>finance_inconv</th>\n",
       "      <th>social_problematic</th>\n",
       "      <th>social_slightly_prob</th>\n",
       "      <th>social_nonprob</th>\n",
       "      <th>health_not_recom</th>\n",
       "      <th>health_priority</th>\n",
       "      <th>health_recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.444955</td>\n",
       "      <td>1.400008</td>\n",
       "      <td>-0.704448</td>\n",
       "      <td>-0.702609</td>\n",
       "      <td>1.997111</td>\n",
       "      <td>-0.494386</td>\n",
       "      <td>-0.496802</td>\n",
       "      <td>-0.501326</td>\n",
       "      <td>-0.506744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.699242</td>\n",
       "      <td>-0.723853</td>\n",
       "      <td>0.991355</td>\n",
       "      <td>-0.991355</td>\n",
       "      <td>1.410334</td>\n",
       "      <td>-0.692219</td>\n",
       "      <td>-0.720143</td>\n",
       "      <td>1.401821</td>\n",
       "      <td>-0.700466</td>\n",
       "      <td>-0.707516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.444955</td>\n",
       "      <td>-0.714282</td>\n",
       "      <td>1.419551</td>\n",
       "      <td>-0.702609</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>2.022710</td>\n",
       "      <td>-0.496802</td>\n",
       "      <td>-0.501326</td>\n",
       "      <td>-0.506744</td>\n",
       "      <td>...</td>\n",
       "      <td>1.430119</td>\n",
       "      <td>-0.723853</td>\n",
       "      <td>-1.008720</td>\n",
       "      <td>1.008720</td>\n",
       "      <td>1.410334</td>\n",
       "      <td>-0.692219</td>\n",
       "      <td>-0.720143</td>\n",
       "      <td>-0.713358</td>\n",
       "      <td>1.427621</td>\n",
       "      <td>-0.707516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.444955</td>\n",
       "      <td>1.400008</td>\n",
       "      <td>-0.704448</td>\n",
       "      <td>-0.702609</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.494386</td>\n",
       "      <td>2.012873</td>\n",
       "      <td>-0.501326</td>\n",
       "      <td>-0.506744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.699242</td>\n",
       "      <td>-0.723853</td>\n",
       "      <td>-1.008720</td>\n",
       "      <td>1.008720</td>\n",
       "      <td>1.410334</td>\n",
       "      <td>-0.692219</td>\n",
       "      <td>-0.720143</td>\n",
       "      <td>1.401821</td>\n",
       "      <td>-0.700466</td>\n",
       "      <td>-0.707516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.444955</td>\n",
       "      <td>-0.714282</td>\n",
       "      <td>-0.704448</td>\n",
       "      <td>1.423266</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.494386</td>\n",
       "      <td>-0.496802</td>\n",
       "      <td>1.994710</td>\n",
       "      <td>-0.506744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.699242</td>\n",
       "      <td>1.381495</td>\n",
       "      <td>-1.008720</td>\n",
       "      <td>1.008720</td>\n",
       "      <td>-0.709052</td>\n",
       "      <td>1.444630</td>\n",
       "      <td>-0.720143</td>\n",
       "      <td>1.401821</td>\n",
       "      <td>-0.700466</td>\n",
       "      <td>-0.707516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.444955</td>\n",
       "      <td>1.400008</td>\n",
       "      <td>-0.704448</td>\n",
       "      <td>-0.702609</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.494386</td>\n",
       "      <td>-0.496802</td>\n",
       "      <td>-0.501326</td>\n",
       "      <td>1.973383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.430119</td>\n",
       "      <td>-0.723853</td>\n",
       "      <td>0.991355</td>\n",
       "      <td>-0.991355</td>\n",
       "      <td>-0.709052</td>\n",
       "      <td>1.444630</td>\n",
       "      <td>-0.720143</td>\n",
       "      <td>1.401821</td>\n",
       "      <td>-0.700466</td>\n",
       "      <td>-0.707516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5178</th>\n",
       "      <td>1</td>\n",
       "      <td>0.449268</td>\n",
       "      <td>-0.714282</td>\n",
       "      <td>-0.704448</td>\n",
       "      <td>1.423266</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.494386</td>\n",
       "      <td>2.012873</td>\n",
       "      <td>-0.501326</td>\n",
       "      <td>-0.506744</td>\n",
       "      <td>...</td>\n",
       "      <td>1.430119</td>\n",
       "      <td>-0.723853</td>\n",
       "      <td>0.991355</td>\n",
       "      <td>-0.991355</td>\n",
       "      <td>1.410334</td>\n",
       "      <td>-0.692219</td>\n",
       "      <td>-0.720143</td>\n",
       "      <td>-0.713358</td>\n",
       "      <td>1.427621</td>\n",
       "      <td>-0.707516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5179</th>\n",
       "      <td>0</td>\n",
       "      <td>0.449268</td>\n",
       "      <td>-0.714282</td>\n",
       "      <td>-0.704448</td>\n",
       "      <td>1.423266</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.494386</td>\n",
       "      <td>-0.496802</td>\n",
       "      <td>-0.501326</td>\n",
       "      <td>1.973383</td>\n",
       "      <td>...</td>\n",
       "      <td>1.430119</td>\n",
       "      <td>-0.723853</td>\n",
       "      <td>0.991355</td>\n",
       "      <td>-0.991355</td>\n",
       "      <td>1.410334</td>\n",
       "      <td>-0.692219</td>\n",
       "      <td>-0.720143</td>\n",
       "      <td>1.401821</td>\n",
       "      <td>-0.700466</td>\n",
       "      <td>-0.707516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5180</th>\n",
       "      <td>0</td>\n",
       "      <td>1.343490</td>\n",
       "      <td>-0.714282</td>\n",
       "      <td>1.419551</td>\n",
       "      <td>-0.702609</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>2.022710</td>\n",
       "      <td>-0.496802</td>\n",
       "      <td>-0.501326</td>\n",
       "      <td>-0.506744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.699242</td>\n",
       "      <td>1.381495</td>\n",
       "      <td>-1.008720</td>\n",
       "      <td>1.008720</td>\n",
       "      <td>1.410334</td>\n",
       "      <td>-0.692219</td>\n",
       "      <td>-0.720143</td>\n",
       "      <td>1.401821</td>\n",
       "      <td>-0.700466</td>\n",
       "      <td>-0.707516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5181</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.444955</td>\n",
       "      <td>1.400008</td>\n",
       "      <td>-0.704448</td>\n",
       "      <td>-0.702609</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>2.022710</td>\n",
       "      <td>-0.496802</td>\n",
       "      <td>-0.501326</td>\n",
       "      <td>-0.506744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.699242</td>\n",
       "      <td>-0.723853</td>\n",
       "      <td>-1.008720</td>\n",
       "      <td>1.008720</td>\n",
       "      <td>-0.709052</td>\n",
       "      <td>1.444630</td>\n",
       "      <td>-0.720143</td>\n",
       "      <td>1.401821</td>\n",
       "      <td>-0.700466</td>\n",
       "      <td>-0.707516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5182</th>\n",
       "      <td>1</td>\n",
       "      <td>1.343490</td>\n",
       "      <td>-0.714282</td>\n",
       "      <td>-0.704448</td>\n",
       "      <td>1.423266</td>\n",
       "      <td>1.997111</td>\n",
       "      <td>-0.494386</td>\n",
       "      <td>-0.496802</td>\n",
       "      <td>-0.501326</td>\n",
       "      <td>-0.506744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.699242</td>\n",
       "      <td>1.381495</td>\n",
       "      <td>0.991355</td>\n",
       "      <td>-0.991355</td>\n",
       "      <td>-0.709052</td>\n",
       "      <td>-0.692219</td>\n",
       "      <td>1.388614</td>\n",
       "      <td>-0.713358</td>\n",
       "      <td>-0.700466</td>\n",
       "      <td>1.413395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5183 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  children  parents_pretentious  parents_usual  parents_great_pret  \\\n",
       "0         0 -0.444955             1.400008      -0.704448           -0.702609   \n",
       "1         3 -0.444955            -0.714282       1.419551           -0.702609   \n",
       "2         0 -0.444955             1.400008      -0.704448           -0.702609   \n",
       "3         0 -0.444955            -0.714282      -0.704448            1.423266   \n",
       "4         0 -0.444955             1.400008      -0.704448           -0.702609   \n",
       "...     ...       ...                  ...            ...                 ...   \n",
       "5178      1  0.449268            -0.714282      -0.704448            1.423266   \n",
       "5179      0  0.449268            -0.714282      -0.704448            1.423266   \n",
       "5180      0  1.343490            -0.714282       1.419551           -0.702609   \n",
       "5181      0 -0.444955             1.400008      -0.704448           -0.702609   \n",
       "5182      1  1.343490            -0.714282      -0.704448            1.423266   \n",
       "\n",
       "      has_nurs_very_crit  has_nurs_critical  has_nurs_proper  \\\n",
       "0               1.997111          -0.494386        -0.496802   \n",
       "1              -0.500723           2.022710        -0.496802   \n",
       "2              -0.500723          -0.494386         2.012873   \n",
       "3              -0.500723          -0.494386        -0.496802   \n",
       "4              -0.500723          -0.494386        -0.496802   \n",
       "...                  ...                ...              ...   \n",
       "5178           -0.500723          -0.494386         2.012873   \n",
       "5179           -0.500723          -0.494386        -0.496802   \n",
       "5180           -0.500723           2.022710        -0.496802   \n",
       "5181           -0.500723           2.022710        -0.496802   \n",
       "5182            1.997111          -0.494386        -0.496802   \n",
       "\n",
       "      has_nurs_improper  has_nurs_less_proper  ...  housing_less_conv  \\\n",
       "0             -0.501326             -0.506744  ...          -0.699242   \n",
       "1             -0.501326             -0.506744  ...           1.430119   \n",
       "2             -0.501326             -0.506744  ...          -0.699242   \n",
       "3              1.994710             -0.506744  ...          -0.699242   \n",
       "4             -0.501326              1.973383  ...           1.430119   \n",
       "...                 ...                   ...  ...                ...   \n",
       "5178          -0.501326             -0.506744  ...           1.430119   \n",
       "5179          -0.501326              1.973383  ...           1.430119   \n",
       "5180          -0.501326             -0.506744  ...          -0.699242   \n",
       "5181          -0.501326             -0.506744  ...          -0.699242   \n",
       "5182          -0.501326             -0.506744  ...          -0.699242   \n",
       "\n",
       "      housing_critical  finance_convenient  finance_inconv  \\\n",
       "0            -0.723853            0.991355       -0.991355   \n",
       "1            -0.723853           -1.008720        1.008720   \n",
       "2            -0.723853           -1.008720        1.008720   \n",
       "3             1.381495           -1.008720        1.008720   \n",
       "4            -0.723853            0.991355       -0.991355   \n",
       "...                ...                 ...             ...   \n",
       "5178         -0.723853            0.991355       -0.991355   \n",
       "5179         -0.723853            0.991355       -0.991355   \n",
       "5180          1.381495           -1.008720        1.008720   \n",
       "5181         -0.723853           -1.008720        1.008720   \n",
       "5182          1.381495            0.991355       -0.991355   \n",
       "\n",
       "      social_problematic  social_slightly_prob  social_nonprob  \\\n",
       "0               1.410334             -0.692219       -0.720143   \n",
       "1               1.410334             -0.692219       -0.720143   \n",
       "2               1.410334             -0.692219       -0.720143   \n",
       "3              -0.709052              1.444630       -0.720143   \n",
       "4              -0.709052              1.444630       -0.720143   \n",
       "...                  ...                   ...             ...   \n",
       "5178            1.410334             -0.692219       -0.720143   \n",
       "5179            1.410334             -0.692219       -0.720143   \n",
       "5180            1.410334             -0.692219       -0.720143   \n",
       "5181           -0.709052              1.444630       -0.720143   \n",
       "5182           -0.709052             -0.692219        1.388614   \n",
       "\n",
       "      health_not_recom  health_priority  health_recommended  \n",
       "0             1.401821        -0.700466           -0.707516  \n",
       "1            -0.713358         1.427621           -0.707516  \n",
       "2             1.401821        -0.700466           -0.707516  \n",
       "3             1.401821        -0.700466           -0.707516  \n",
       "4             1.401821        -0.700466           -0.707516  \n",
       "...                ...              ...                 ...  \n",
       "5178         -0.713358         1.427621           -0.707516  \n",
       "5179          1.401821        -0.700466           -0.707516  \n",
       "5180          1.401821        -0.700466           -0.707516  \n",
       "5181          1.401821        -0.700466           -0.707516  \n",
       "5182         -0.713358        -0.700466            1.413395  \n",
       "\n",
       "[5183 rows x 25 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../utils/data/inference/Nursery_prepared_train.csv', sep=',', engine='python')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model accuracy:  0.9849537037037037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from art.estimators.classification.scikitlearn import ScikitlearnRandomForestClassifier\n",
    "\n",
    "features = df.drop(['label'], axis=1)\n",
    "labels = df.loc[:, 'label']\n",
    "model = RandomForestClassifier()\n",
    "model.fit(features, labels)\n",
    "x_train = features.to_numpy()\n",
    "y_train = labels.to_numpy()\n",
    "\n",
    "art_classifier = ScikitlearnRandomForestClassifier(model)\n",
    "\n",
    "df_test = pd.read_csv('../utils/data/inference/Nursery_prepared_test.csv', sep=',', engine='python')\n",
    "features_test = df_test.drop(['label'], axis=1)\n",
    "labels_test = df_test.loc[:, 'label']\n",
    "x_test = features_test.to_numpy()\n",
    "y_test = labels_test.to_numpy()\n",
    "\n",
    "print('Base model accuracy: ', model.score(features_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack\n",
    "### Rule-based attack\n",
    "The rule-based attack uses the simple rule to determine membership in the training data: if the model's prediction for a sample is correct, then it is a member. Otherwise, it is not a member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.01504629629629628\n",
      "0.6716398713826367\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from art.attacks.inference import MembershipInferenceBlackBoxRuleBased\n",
    "\n",
    "attack = MembershipInferenceBlackBoxRuleBased(art_classifier)\n",
    "\n",
    "# infer attacked feature\n",
    "inferred_train = attack.infer(x_train, y_train)\n",
    "inferred_test = attack.infer(x_test, y_test)\n",
    "\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train) / len(inferred_train)\n",
    "test_acc = 1 - (np.sum(inferred_test) / len(inferred_test))\n",
    "acc = (train_acc * len(inferred_train) + test_acc * len(inferred_test)) / (len(inferred_train) + len(inferred_test))\n",
    "print(train_acc)\n",
    "print(test_acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that for 67% of the data, membership status is inferred correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6699844881075491, 1.0)\n"
     ]
    }
   ],
   "source": [
    "def calc_precision_recall(predicted, actual, positive_value=1):\n",
    "    score = 0  # both predicted and actual are positive\n",
    "    num_positive_predicted = 0  # predicted positive\n",
    "    num_positive_actual = 0  # actual positive\n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i] == positive_value:\n",
    "            num_positive_predicted += 1\n",
    "        if actual[i] == positive_value:\n",
    "            num_positive_actual += 1\n",
    "        if predicted[i] == actual[i]:\n",
    "            if predicted[i] == positive_value:\n",
    "                score += 1\n",
    "    \n",
    "    if num_positive_predicted == 0:\n",
    "        precision = 1\n",
    "    else:\n",
    "        precision = score / num_positive_predicted  # the fraction of predicted “Yes” responses that are correct\n",
    "    if num_positive_actual == 0:\n",
    "        recall = 1\n",
    "    else:\n",
    "        recall = score / num_positive_actual  # the fraction of “Yes” responses that are predicted correctly\n",
    "\n",
    "    return precision, recall\n",
    "\n",
    "# rule-based\n",
    "print(calc_precision_recall(np.concatenate((inferred_train, inferred_test)), \n",
    "                            np.concatenate((np.ones(len(inferred_train)), np.zeros(len(inferred_test))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black-box attack\n",
    "The black-box attack basically trains an additional classifier (called the attack model) to predict the membership status of a sample. It can use as input to the learning process probabilities/logits or losses, depending on the type of model and provided configuration.\n",
    "#### Train attack model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.inference import MembershipInferenceBlackBox\n",
    "\n",
    "attack_train_ratio = 0.5\n",
    "attack_train_size = int(len(x_train) * attack_train_ratio)\n",
    "attack_test_size = int(len(x_test) * attack_train_ratio)\n",
    "\n",
    "bb_attack = MembershipInferenceBlackBox(art_classifier)\n",
    "\n",
    "# train attack model\n",
    "bb_attack.fit(x_train[:attack_train_size], y_train[:attack_train_size],\n",
    "              x_test[:attack_test_size], y_test[:attack_test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infer sensitive feature and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9548611111111112\n",
      "0.1450617283950617\n",
      "0.6849279835390947\n"
     ]
    }
   ],
   "source": [
    "# get inferred values\n",
    "inferred_train_bb = bb_attack.infer(x_train[attack_train_size:], y_train[attack_train_size:])\n",
    "inferred_test_bb = bb_attack.infer(x_test[attack_test_size:], y_test[attack_test_size:])\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train_bb) / len(inferred_train_bb)\n",
    "test_acc = 1 - (np.sum(inferred_test_bb) / len(inferred_test_bb))\n",
    "acc = (train_acc * len(inferred_train_bb) + test_acc * len(inferred_test_bb)) / (len(inferred_train_bb) + len(inferred_test_bb))\n",
    "print(train_acc)\n",
    "print(test_acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acheives almost the same results as the rule-based attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6907619313424505, 0.9548611111111112)\n"
     ]
    }
   ],
   "source": [
    "# black-box\n",
    "print(calc_precision_recall(np.concatenate((inferred_train_bb, inferred_test_bb)), \n",
    "                            np.concatenate((np.ones(len(inferred_train_bb)), np.zeros(len(inferred_test_bb))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model accuracy:  0.9749228395061729\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from art.estimators.classification.pytorch import PyTorchClassifier\n",
    "\n",
    "class ModelToAttack(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, num_features):\n",
    "        super(ModelToAttack, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "                nn.Linear(num_features, 1024),\n",
    "                nn.Tanh(), )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "                nn.Linear(1024, 512),\n",
    "                nn.Tanh(), )\n",
    "\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "        return self.classifier(out)\n",
    "\n",
    "mlp_model = ModelToAttack(4, 24)\n",
    "mlp_model = torch.nn.DataParallel(mlp_model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mlp_model.parameters(), lr=0.0001)\n",
    "\n",
    "class NurseryDataset(Dataset):\n",
    "    def __init__(self, x, y=None):\n",
    "        self.x = torch.from_numpy(x.astype(np.float64)).type(torch.FloatTensor)\n",
    "\n",
    "        if y is not None:\n",
    "            self.y = torch.from_numpy(y.astype(np.int8)).type(torch.LongTensor)\n",
    "        else:\n",
    "            self.y = torch.zeros(x.shape[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.x):\n",
    "            raise IndexError(\"Invalid Index\")\n",
    "\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "train_set = NurseryDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_set, batch_size=100, shuffle=True, num_workers=0)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for (input, targets) in train_loader:\n",
    "        input, targets = torch.autograd.Variable(input), torch.autograd.Variable(targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = mlp_model(input)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "mlp_art_model = PyTorchClassifier(model=mlp_model, loss=criterion, optimizer=optimizer, input_shape=(24,), nb_classes=4)\n",
    "\n",
    "pred = np.array([np.argmax(arr) for arr in mlp_art_model.predict(x_test.astype(np.float32))])\n",
    "\n",
    "print('Base model accuracy: ', np.sum(pred == y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule-based attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9814779085471734\n",
      "0.025077160493827133\n",
      "0.662636655948553\n",
      "(0.6681113737851326, 0.9814779085471734)\n"
     ]
    }
   ],
   "source": [
    "mlp_attack = MembershipInferenceBlackBoxRuleBased(mlp_art_model)\n",
    "\n",
    "# infer \n",
    "mlp_inferred_train = mlp_attack.infer(x_train.astype(np.float32), y_train)\n",
    "mlp_inferred_test = mlp_attack.infer(x_test.astype(np.float32), y_test)\n",
    "\n",
    "# check accuracy\n",
    "mlp_train_acc = np.sum(mlp_inferred_train) / len(mlp_inferred_train)\n",
    "mlp_test_acc = 1 - (np.sum(mlp_inferred_test) / len(mlp_inferred_test))\n",
    "mlp_acc = (mlp_train_acc * len(mlp_inferred_train) + mlp_test_acc * len(mlp_inferred_test)) / (len(mlp_inferred_train) + len(mlp_inferred_test))\n",
    "print(mlp_train_acc)\n",
    "print(mlp_test_acc)\n",
    "print(mlp_acc)\n",
    "\n",
    "print(calc_precision_recall(np.concatenate((mlp_inferred_train, mlp_inferred_test)), \n",
    "                            np.concatenate((np.ones(len(mlp_inferred_train)), np.zeros(len(mlp_inferred_test))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black-box attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8782558363881922\n",
      "0.49151234567901236\n",
      "0.7493247588424438\n",
      "(0.7754684838160136, 0.8782558363881922)\n"
     ]
    }
   ],
   "source": [
    "mlp_attack_bb = MembershipInferenceBlackBox(mlp_art_model, attack_model_type='rf')\n",
    "\n",
    "# train attack model\n",
    "mlp_attack_bb.fit(x_train[:attack_train_size].astype(np.float32), y_train[:attack_train_size],\n",
    "              x_test[:attack_test_size].astype(np.float32), y_test[:attack_test_size])\n",
    "\n",
    "# infer \n",
    "mlp_inferred_train_bb = mlp_attack_bb.infer(x_train.astype(np.float32), y_train)\n",
    "mlp_inferred_test_bb = mlp_attack_bb.infer(x_test.astype(np.float32), y_test)\n",
    "\n",
    "# check accuracy\n",
    "mlp_train_acc_bb = np.sum(mlp_inferred_train_bb) / len(mlp_inferred_train_bb)\n",
    "mlp_test_acc_bb = 1 - (np.sum(mlp_inferred_test_bb) / len(mlp_inferred_test_bb))\n",
    "mlp_acc_bb = (mlp_train_acc_bb * len(mlp_inferred_train_bb) + mlp_test_acc_bb * len(mlp_inferred_test_bb)) / (len(mlp_inferred_train_bb) + len(mlp_inferred_test_bb))\n",
    "print(mlp_train_acc_bb)\n",
    "print(mlp_test_acc_bb)\n",
    "print(mlp_acc_bb)\n",
    "\n",
    "print(calc_precision_recall(np.concatenate((mlp_inferred_train_bb, mlp_inferred_test_bb)), \n",
    "                            np.concatenate((np.ones(len(mlp_inferred_train_bb)), np.zeros(len(mlp_inferred_test_bb))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a random forest as the attack model we were able to acheive better performance than the rule-based attack, both in terms of accuracy and precision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
