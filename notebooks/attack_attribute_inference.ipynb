{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running attribute inference attacks on the Nursery data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will show how to run both black-box and white-box inference attacks. This will be demonstrated on the Nursery dataset (original dataset can be found here: https://archive.ics.uci.edu/ml/datasets/nursery). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "In order to mount a successful attribute inference attack, the attacked feature must be categorical, and with a relatively small number of possible values (preferably binary, but should at least be less then the number of label classes).\n",
    "\n",
    "In the case of the nursery dataset, the sensitive feature we want to infer is the 'social' feature. In the original dataset this is a categorical feature with 3 possible values. To make the attack more successful, we reduced this to two possible feature values by assigning the original value 'problematic' the new value 1, and the other original values were assigned the new value 0.\n",
    "\n",
    "We have also already preprocessed the dataset such that all categorical features are one-hot encoded, and the data was scaled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>children</th>\n",
       "      <th>social</th>\n",
       "      <th>parents_pretentious</th>\n",
       "      <th>parents_great_pret</th>\n",
       "      <th>parents_usual</th>\n",
       "      <th>has_nurs_very_crit</th>\n",
       "      <th>has_nurs_improper</th>\n",
       "      <th>has_nurs_proper</th>\n",
       "      <th>has_nurs_critical</th>\n",
       "      <th>...</th>\n",
       "      <th>form_incomplete</th>\n",
       "      <th>form_foster</th>\n",
       "      <th>housing_critical</th>\n",
       "      <th>housing_convenient</th>\n",
       "      <th>housing_less_conv</th>\n",
       "      <th>finance_convenient</th>\n",
       "      <th>finance_inconv</th>\n",
       "      <th>health_priority</th>\n",
       "      <th>health_recommended</th>\n",
       "      <th>health_not_recom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>-0.704142</td>\n",
       "      <td>1.434509</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>2.000724</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567324</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>1.428869</td>\n",
       "      <td>-0.711511</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>0.985252</td>\n",
       "      <td>-0.985252</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>-0.704142</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>1.402427</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>2.003141</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567324</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>-0.699854</td>\n",
       "      <td>1.405459</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>-1.014968</td>\n",
       "      <td>1.014968</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.335242</td>\n",
       "      <td>1.420169</td>\n",
       "      <td>1.434509</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>1.997111</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567324</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>-0.699854</td>\n",
       "      <td>-0.711511</td>\n",
       "      <td>1.408503</td>\n",
       "      <td>-1.014968</td>\n",
       "      <td>1.014968</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>-0.704142</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>1.978079</td>\n",
       "      <td>...</td>\n",
       "      <td>1.762661</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>-0.699854</td>\n",
       "      <td>1.405459</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>0.985252</td>\n",
       "      <td>-0.985252</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>-0.704142</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>1.997111</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567324</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>1.428869</td>\n",
       "      <td>-0.711511</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>0.985252</td>\n",
       "      <td>-0.985252</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5178</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.337132</td>\n",
       "      <td>-0.704142</td>\n",
       "      <td>1.434509</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>1.978079</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567324</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>-0.699854</td>\n",
       "      <td>-0.711511</td>\n",
       "      <td>1.408503</td>\n",
       "      <td>-1.014968</td>\n",
       "      <td>1.014968</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>1.432625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5179</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.337132</td>\n",
       "      <td>1.420169</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>1.402427</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>2.003141</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>1.762661</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>-0.699854</td>\n",
       "      <td>1.405459</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>-1.014968</td>\n",
       "      <td>1.014968</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5180</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.446341</td>\n",
       "      <td>1.420169</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>2.003141</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>1.762661</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>-0.699854</td>\n",
       "      <td>1.405459</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>-1.014968</td>\n",
       "      <td>1.014968</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5181</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.446341</td>\n",
       "      <td>-0.704142</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>2.000724</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567324</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>1.428869</td>\n",
       "      <td>-0.711511</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>0.985252</td>\n",
       "      <td>-0.985252</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5182</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.337132</td>\n",
       "      <td>1.420169</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>1.997111</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>1.762661</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>-0.699854</td>\n",
       "      <td>1.405459</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>0.985252</td>\n",
       "      <td>-0.985252</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5183 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  children    social  parents_pretentious  parents_great_pret  \\\n",
       "0         1  0.444450 -0.704142             1.434509           -0.713050   \n",
       "1         1  0.444450 -0.704142            -0.697102            1.402427   \n",
       "2         3  1.335242  1.420169             1.434509           -0.713050   \n",
       "3         3  0.444450 -0.704142            -0.697102           -0.713050   \n",
       "4         3  0.444450 -0.704142            -0.697102           -0.713050   \n",
       "...     ...       ...       ...                  ...                 ...   \n",
       "5178      0 -1.337132 -0.704142             1.434509           -0.713050   \n",
       "5179      1 -1.337132  1.420169            -0.697102            1.402427   \n",
       "5180      3 -0.446341  1.420169            -0.697102           -0.713050   \n",
       "5181      1 -0.446341 -0.704142            -0.697102           -0.713050   \n",
       "5182      3 -1.337132  1.420169            -0.697102           -0.713050   \n",
       "\n",
       "      parents_usual  has_nurs_very_crit  has_nurs_improper  has_nurs_proper  \\\n",
       "0         -0.711204            2.000724          -0.499216        -0.500723   \n",
       "1         -0.711204           -0.499819           2.003141        -0.500723   \n",
       "2         -0.711204           -0.499819          -0.499216         1.997111   \n",
       "3          1.406067           -0.499819          -0.499216        -0.500723   \n",
       "4          1.406067           -0.499819          -0.499216         1.997111   \n",
       "...             ...                 ...                ...              ...   \n",
       "5178      -0.711204           -0.499819          -0.499216        -0.500723   \n",
       "5179      -0.711204           -0.499819           2.003141        -0.500723   \n",
       "5180       1.406067           -0.499819           2.003141        -0.500723   \n",
       "5181       1.406067            2.000724          -0.499216        -0.500723   \n",
       "5182       1.406067           -0.499819          -0.499216         1.997111   \n",
       "\n",
       "      has_nurs_critical  ...  form_incomplete  form_foster  housing_critical  \\\n",
       "0             -0.505541  ...        -0.567324    -0.577425          1.428869   \n",
       "1             -0.505541  ...        -0.567324    -0.577425         -0.699854   \n",
       "2             -0.505541  ...        -0.567324    -0.577425         -0.699854   \n",
       "3              1.978079  ...         1.762661    -0.577425         -0.699854   \n",
       "4             -0.505541  ...        -0.567324    -0.577425          1.428869   \n",
       "...                 ...  ...              ...          ...               ...   \n",
       "5178           1.978079  ...        -0.567324    -0.577425         -0.699854   \n",
       "5179          -0.505541  ...         1.762661    -0.577425         -0.699854   \n",
       "5180          -0.505541  ...         1.762661    -0.577425         -0.699854   \n",
       "5181          -0.505541  ...        -0.567324    -0.577425          1.428869   \n",
       "5182          -0.505541  ...         1.762661    -0.577425         -0.699854   \n",
       "\n",
       "      housing_convenient  housing_less_conv  finance_convenient  \\\n",
       "0              -0.711511          -0.709974            0.985252   \n",
       "1               1.405459          -0.709974           -1.014968   \n",
       "2              -0.711511           1.408503           -1.014968   \n",
       "3               1.405459          -0.709974            0.985252   \n",
       "4              -0.711511          -0.709974            0.985252   \n",
       "...                  ...                ...                 ...   \n",
       "5178           -0.711511           1.408503           -1.014968   \n",
       "5179            1.405459          -0.709974           -1.014968   \n",
       "5180            1.405459          -0.709974           -1.014968   \n",
       "5181           -0.711511          -0.709974            0.985252   \n",
       "5182            1.405459          -0.709974            0.985252   \n",
       "\n",
       "      finance_inconv  health_priority  health_recommended  health_not_recom  \n",
       "0          -0.985252         1.399405           -0.708745         -0.698019  \n",
       "1           1.014968         1.399405           -0.708745         -0.698019  \n",
       "2           1.014968        -0.714590            1.410946         -0.698019  \n",
       "3          -0.985252         1.399405           -0.708745         -0.698019  \n",
       "4          -0.985252         1.399405           -0.708745         -0.698019  \n",
       "...              ...              ...                 ...               ...  \n",
       "5178        1.014968        -0.714590           -0.708745          1.432625  \n",
       "5179        1.014968        -0.714590            1.410946         -0.698019  \n",
       "5180        1.014968        -0.714590            1.410946         -0.698019  \n",
       "5181       -0.985252         1.399405           -0.708745         -0.698019  \n",
       "5182       -0.985252        -0.714590            1.410946         -0.698019  \n",
       "\n",
       "[5183 rows x 23 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../utils/data/inference/Nursery_social_prepared_train.csv', sep=',', engine='python')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model accuracy:  0.6851851851851852\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from art.estimators.classification.scikitlearn import ScikitlearnDecisionTreeClassifier\n",
    "\n",
    "features = df.drop(['label'], axis=1)\n",
    "labels = df.loc[:, 'label']\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(features, labels)\n",
    "\n",
    "art_classifier = ScikitlearnDecisionTreeClassifier(model)\n",
    "\n",
    "df_test = pd.read_csv('../utils/data/inference/Nursery_social_prepared_test.csv', sep=',', engine='python')\n",
    "features_test = df_test.drop(['label'], axis=1)\n",
    "labels_test = df_test.loc[:, 'label']\n",
    "test_data = features_test.to_numpy()\n",
    "\n",
    "print('Base model accuracy: ', model.score(features_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack\n",
    "### Black-box attack\n",
    "The black-box attack basically trains an additional classifier (called the attack model) to predict the attacked feature's value from the remaining n-1 features as well as the original (attacked) model's predictions.\n",
    "#### Train attack model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from art.attacks.inference import AttributeInferenceBlackBox\n",
    "\n",
    "attack_feature = 1\n",
    "data = features.to_numpy()\n",
    "\n",
    "# training data without attacked feature\n",
    "x_train_for_attack = np.delete(data, attack_feature, 1)\n",
    "# only attacked feature\n",
    "x_train_feature = data[:, attack_feature].copy().reshape(-1, 1)\n",
    "\n",
    "bb_attack = AttributeInferenceBlackBox(art_classifier, attack_feature=attack_feature)\n",
    "\n",
    "# get original model's predictions\n",
    "x_train_predictions = np.array([np.argmax(arr) for arr in art_classifier.predict(data)]).reshape(-1,1)\n",
    "\n",
    "# train attack model\n",
    "bb_attack.fit(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infer sensitive feature and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6158595408064828\n"
     ]
    }
   ],
   "source": [
    "# get inferred values\n",
    "values = [-0.704141531, 1.420169037]\n",
    "inferred_train_bb = bb_attack.infer(x_train_for_attack, x_train_predictions, values=values)\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train_bb == x_train_feature.reshape(1,-1)) / len(inferred_train_bb)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that for 61% of the training set, the attacked feature is inferred correctly using this attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whitebox attacks\n",
    "These two attacks do not train any additional model, they simply use additional information coded within the attacked decision tree model to compute the probability of each value of the attacked feature and outputs the value with the highest probability.\n",
    "### First attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6183677406907196\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.inference import AttributeInferenceWhiteBoxLifestyleDecisionTree\n",
    "\n",
    "wb_attack = AttributeInferenceWhiteBoxLifestyleDecisionTree(art_classifier, attack_feature=attack_feature)\n",
    "\n",
    "priors = [3465 / 5183, 1718 / 5183]\n",
    "\n",
    "# get inferred values\n",
    "inferred_train_wb1 = wb_attack.infer(x_train_for_attack, x_train_predictions, values=values, priors=priors)\n",
    "\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train_wb1 == x_train_feature.reshape(1,-1)) / len(inferred_train_wb1)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6905267219756898\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.inference import AttributeInferenceWhiteBoxDecisionTree\n",
    "\n",
    "wb2_attack = AttributeInferenceWhiteBoxDecisionTree(art_classifier, attack_feature=attack_feature)\n",
    "\n",
    "# get inferred values\n",
    "inferred_train_wb2 = wb2_attack.infer(x_train_for_attack, x_train_predictions, values=values, priors=priors)\n",
    "\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train_wb2 == x_train_feature.reshape(1,-1)) / len(inferred_train_wb2)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The white-box attacks are able to correctly infer the attacked feature value in 61% and 69% of the test set respectively. \n",
    "\n",
    "Now let's check the precision and recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.394919168591224, 0.29860302677532014)\n",
      "(0.3402948402948403, 0.1612339930151339)\n",
      "(0.5874233128834356, 0.2229336437718277)\n"
     ]
    }
   ],
   "source": [
    "def calc_precision_recall(predicted, actual, positive_value=1):\n",
    "    score = 0  # both predicted and actual are positive\n",
    "    num_positive_predicted = 0  # predicted positive\n",
    "    num_positive_actual = 0  # actual positive\n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i] == positive_value:\n",
    "            num_positive_predicted += 1\n",
    "        if actual[i] == positive_value:\n",
    "            num_positive_actual += 1\n",
    "        if predicted[i] == actual[i]:\n",
    "            if predicted[i] == positive_value:\n",
    "                score += 1\n",
    "    \n",
    "    if num_positive_predicted == 0:\n",
    "        precision = 1\n",
    "    else:\n",
    "        precision = score / num_positive_predicted  # the fraction of predicted “Yes” responses that are correct\n",
    "    if num_positive_actual == 0:\n",
    "        recall = 1\n",
    "    else:\n",
    "        recall = score / num_positive_actual  # the fraction of “Yes” responses that are predicted correctly\n",
    "\n",
    "    return precision, recall\n",
    "    \n",
    "# black-box\n",
    "print(calc_precision_recall(inferred_train_bb, x_train_feature, positive_value=1.420169037))\n",
    "# white-box 1\n",
    "print(calc_precision_recall(inferred_train_wb1, x_train_feature, positive_value=1.420169037))\n",
    "# white-box 2\n",
    "print(calc_precision_recall(inferred_train_wb2, x_train_feature, positive_value=1.420169037))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
