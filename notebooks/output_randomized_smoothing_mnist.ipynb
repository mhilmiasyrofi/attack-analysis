{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aPIA-10zdv4P"
   },
   "source": [
    "## ART Randomized Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CGDOyI0HgDfx",
    "outputId": "2d61711f-6f8a-41b5-f05c-1085fd00fa13"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "from art.config import ART_DATA_PATH\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from art.estimators.certification.randomized_smoothing import TensorFlowV2RandomizedSmoothing\n",
    "from art.utils import load_dataset, get_file, compute_accuracy\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FqXvuMM9dv4U"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z9OztmSidv4V"
   },
   "outputs": [],
   "source": [
    "# Read MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset('mnist')\n",
    "\n",
    "nb_classes = 10\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "num_samples_test = 250\n",
    "x_test = x_test[0:num_samples_test].astype(np.float32)\n",
    "y_test = y_test[0:num_samples_test]\n",
    "\n",
    "x_train = x_train.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xDCzquK1dv4X"
   },
   "source": [
    "### Train classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-mh9wSAHm-Z"
   },
   "outputs": [],
   "source": [
    "# Create convolutional neural network model\n",
    "def get_model(input_shape, min_, max_):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 40\n",
    "batch_size = 128\n",
    "sample_size = 100\n",
    "alpha = 0.001\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "def train_step(model, images, labels):        \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tGbe8Cjmdv4a"
   },
   "outputs": [],
   "source": [
    "# Construct and train a convolutional neural network in standard (non-smoothed) classifier\n",
    "\n",
    "classifier = TensorFlowV2Classifier(model=get_model(input_shape, min_, max_),\n",
    "                                    nb_classes=nb_classes,\n",
    "                                    input_shape=input_shape,\n",
    "                                    loss_object=loss_object,\n",
    "                                    train_step=train_step,\n",
    "                                    channels_first=False,\n",
    "                                    clip_values=(min_, max_))\n",
    "\n",
    "classifier.fit(x_train, y_train, nb_epochs=nb_epochs, batch_size=batch_size)\n",
    "\n",
    "sigma_0 = 0.5\n",
    "\n",
    "classifier_rs_0 = TensorFlowV2RandomizedSmoothing(model=classifier.model,\n",
    "                                                  nb_classes=nb_classes,\n",
    "                                                  input_shape=input_shape,\n",
    "                                                  loss_object=loss_object,\n",
    "                                                  train_step=train_step,\n",
    "                                                  channels_first=False,\n",
    "                                                  clip_values=(min_, max_),\n",
    "                                                  sample_size=sample_size,\n",
    "                                                  scale=sigma_0,\n",
    "                                                  alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train smoothed classifier, sigma = 0.25\n",
    "\n",
    "sigma_1 = 0.25\n",
    "\n",
    "classifier_rs_1 = TensorFlowV2RandomizedSmoothing(model=get_model(input_shape, min_, max_),\n",
    "                                                 nb_classes=nb_classes,\n",
    "                                                 input_shape=input_shape,\n",
    "                                                 loss_object=loss_object,\n",
    "                                                 train_step=train_step,\n",
    "                                                 channels_first=False,\n",
    "                                                 clip_values=(min_, max_),\n",
    "                                                 sample_size=sample_size,\n",
    "                                                 scale=sigma_1,\n",
    "                                                 alpha=alpha)\n",
    "\n",
    "classifier_rs_1.fit(x_train, y_train, nb_epochs=nb_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train smoothed classifier, sigma = 0.5\n",
    "\n",
    "sigma_2 = 0.5\n",
    "\n",
    "classifier_rs_2 = TensorFlowV2RandomizedSmoothing(model=get_model(input_shape, min_, max_),\n",
    "                                                  nb_classes=nb_classes,\n",
    "                                                  input_shape=input_shape,\n",
    "                                                  loss_object=loss_object,\n",
    "                                                  train_step=train_step,\n",
    "                                                  channels_first=False,\n",
    "                                                  clip_values=(min_, max_),\n",
    "                                                  sample_size=sample_size,\n",
    "                                                  scale=sigma_2,\n",
    "                                                  alpha=alpha)\n",
    "\n",
    "classifier_rs_2.fit(x_train, y_train, nb_epochs=nb_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kukXRDcedv4j"
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "jcPkXptcdv4k",
    "outputId": "ee65b562-0839-483b-9b1f-b7c911e3131a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Randomized smoothing: 100%|██████████| 250/250 [00:04<00:00, 58.59it/s]\n",
      "Randomized smoothing: 100%|██████████| 250/250 [00:04<00:00, 58.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original test data:\n",
      "Original Classifier\n",
      "Accuracy: 1.0\n",
      "Coverage: 1.0\n",
      "\n",
      "Smoothed Classifier, sigma=0.25\n",
      "Accuracy: 0.9959839357429718\n",
      "Coverage: 0.996\n",
      "\n",
      "Smoothed Classifier, sigma=0.5\n",
      "Accuracy: 1.0\n",
      "Coverage: 0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# compare prediction of randomized smoothed models to original model\n",
    "x_preds = classifier.predict(x_test)\n",
    "x_preds_rs_1 = classifier_rs_1.predict(x_test)\n",
    "x_preds_rs_2 = classifier_rs_2.predict(x_test)\n",
    "\n",
    "acc, cov = compute_accuracy(x_preds, y_test)\n",
    "acc_rs_1, cov_rs_1 = compute_accuracy(x_preds_rs_1, y_test)\n",
    "acc_rs_2, cov_rs_2 = compute_accuracy(x_preds_rs_2, y_test)\n",
    "\n",
    "print(\"\\nOriginal test data:\")\n",
    "print(\"Original Classifier\")\n",
    "print(\"Accuracy: {}\".format(acc))\n",
    "print(\"Coverage: {}\".format(cov))\n",
    "\n",
    "print(\"\\nSmoothed Classifier, sigma=\" + str(sigma_1))\n",
    "print(\"Accuracy: {}\".format(acc_rs_1))\n",
    "print(\"Coverage: {}\".format(cov_rs_1))\n",
    "\n",
    "print(\"\\nSmoothed Classifier, sigma=\" + str(sigma_2))\n",
    "print(\"Accuracy: {}\".format(acc_rs_2))\n",
    "print(\"Coverage: {}\".format(cov_rs_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hqea3xvMdv4n"
   },
   "source": [
    "## Certification of Accuracy and L2-Radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D6Va8ST8dv4n"
   },
   "outputs": [],
   "source": [
    "# Calculate certification accuracy for a given radius\n",
    "def getCertAcc(radius, pred, y_test):\n",
    "\n",
    "    rad_list = np.linspace(0, 2.25, 201)\n",
    "    cert_acc = []\n",
    "    num_cert = len(radius)\n",
    "    \n",
    "    for r in rad_list:\n",
    "        rad_idx = np.where(radius >= r)[0]\n",
    "        y_test_subset = y_test[rad_idx]\n",
    "        cert_acc.append(np.sum(pred[rad_idx] == np.argmax(y_test_subset, axis=1)) / num_cert)\n",
    "        \n",
    "    return cert_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPWY6KFMdv4p"
   },
   "outputs": [],
   "source": [
    "# Compute certification\n",
    "prediction_0, radius_0 = classifier_rs_0.certify(x_test, n=500)\n",
    "prediction_1, radius_1 = classifier_rs_1.certify(x_test, n=500)\n",
    "prediction_2, radius_2 = classifier_rs_2.certify(x_test, n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "ZZv5wDHSdv4s",
    "outputId": "a6fbe7ba-dfbb-47bd-8e56-794fb689cb14"
   },
   "outputs": [],
   "source": [
    "# Plot certification accuracy w.r.t. to radius\n",
    "rad_list = np.linspace(0, 2.25, 201)\n",
    "plt.plot(rad_list, getCertAcc(radius_0, prediction_0, y_test), 'r-', label='original')\n",
    "plt.plot(rad_list, getCertAcc(radius_1, prediction_1, y_test), '-', color='green',\n",
    "         label='smoothed, $\\sigma=$' + str(sigma_1))\n",
    "plt.plot(rad_list, getCertAcc(radius_2, prediction_2, y_test), '-', color='blue',\n",
    "         label='smoothed, $\\sigma=$' + str(sigma_2))\n",
    "plt.xlabel('radius')\n",
    "plt.ylabel('certified accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "randomized_smoothing_mnist.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
